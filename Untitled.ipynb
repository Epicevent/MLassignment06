{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10001, 1027])\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([#transforms.Resize((256,256)),  \n",
    "                                transforms.Grayscale(),\t\t# the code transforms.Graysclae() is for changing the size [3,100,100] to [1, 100, 100] (notice : [channel, height, width] )\n",
    "                                transforms.ToTensor(),])\n",
    "\n",
    "\n",
    "#train_data_path = 'relative path of training data set'\n",
    "train_data_path = '../../horse-or-human/train'\n",
    "trainset = torchvision.datasets.ImageFolder(root=train_data_path, transform=transform)\n",
    "# change the valuse of batch_size, num_workers for your program\n",
    "# if shuffle=True, the data reshuffled at every epoch \n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1500, shuffle=False, num_workers=1)  \n",
    "\n",
    "\n",
    "validation_data_path = '../../horse-or-human/validation'\n",
    "valset = torchvision.datasets.ImageFolder(root=validation_data_path, transform=transform)\n",
    "# change the valuse of batch_size, num_workers for your program\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=1500, shuffle=False, num_workers=1)  \n",
    "\n",
    "\n",
    "\n",
    " # since batch size is larger than number of data , It works well.\n",
    "for i, data in enumerate(trainloader):\n",
    "    train_inputs, train_labels = data\n",
    "    train_inputs = train_inputs.view(train_inputs.shape[2]*train_inputs.shape[3],train_inputs.shape[0])\n",
    "for i, data in enumerate(valloader):\n",
    "    test_inputs, test_labels = data\n",
    "    test_inputs = test_inputs.view(test_inputs.shape[2]*test_inputs.shape[3],test_inputs.shape[0])\n",
    "    \n",
    "Intercept_test = torch.ones(1,test_inputs.shape[1])\n",
    "Intercept_train = torch.ones(1,train_inputs.shape[1])\n",
    "\n",
    "test_inputs = torch.cat([test_inputs,Intercept_test],dim = 0)\n",
    "train_inputs = torch.cat([train_inputs,Intercept_train],dim = 0)\n",
    "\n",
    "print(train_inputs.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network architecture\n",
    "\n",
    "## First layer\n",
    "\n",
    "$$Z^{[1]} = W^{[1]}X + b^{[1]}$$\n",
    "\n",
    "$$A^{[1]} = g(Z^{[1]})$$\n",
    "\n",
    "where $X$ denotes the input data ( images : 10000 *numof images ) and size of $W^[1]$ is (464, 10000) . \n",
    "\n",
    "\n",
    "## second layer\n",
    "\n",
    "$$Z^{[2]} = W^{[2]}A^{[1]} + b^{[2]}$$\n",
    "\n",
    "$$A^{[2]} = g(Z^{[2]})$$\n",
    "\n",
    "where size of $W^[2]$ is (21, 464). \n",
    "\n",
    "## Third layer\n",
    "\n",
    "$$Z^{[3]} = W^{[3]}A^{[2]} + b^{[3]}$$\n",
    "\n",
    "$$A^{[3]} = g(Z^{[3]})$$\n",
    "\n",
    "where size of $W^[2]$ is (1, 21). \n",
    "\n",
    "## Activation \n",
    "\n",
    "g is the sigmoid function.\n",
    "\n",
    "## Loss\n",
    "\n",
    "let $n$ denotes the number of the images.\n",
    "$$ Loss = \\sum_{i=1}^{n}{f_i} + {{\\lambda} \\over {2}} F $$\n",
    "\n",
    "where $F$ denotes the sum of Frobenius Norm of $W^{[i]} \\quad i=1,2,3$ based on $L^2_2$norm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class network_updater:\n",
    "    def __init__(self,num_node_1,num_node_2 ,regular_lambda): \n",
    "        num_node_0 = 10000\n",
    "        num_node_3 = 1 \n",
    "        self.weight_1 = torch.rand(num_node_1,num_node_0+1)*0.01\n",
    "        \n",
    "        \n",
    "        self.weight_2 = torch.rand(num_node_2,num_node_1 +1 )*0.01\n",
    "        \n",
    "        \n",
    "        self.weight_3 = torch.rand(num_node_3,num_node_2+1)*0.01\n",
    "     \n",
    "        self.regular_lambda = regular_lambda\n",
    "        self.N1 = 0\n",
    "        self.N2 = 0\n",
    "        self.N3 = 0\n",
    "\n",
    "        \n",
    "   \n",
    "    def norm(self,weight_cat): \n",
    "        weight = weight_cat[:,0:-1]\n",
    "        return weight.norm()\n",
    "    \n",
    "    def y_hat(self,images):# images with intercept\n",
    "        num_training_data = images.shape[1] \n",
    "        Intercept_hidden1 = torch.ones(1,num_training_data)\n",
    "        Intercept_hidden2 = torch.ones(1,num_training_data)\n",
    "        \n",
    "        hidden1 = torch.sigmoid(torch.mm(self.weight_1,images))\n",
    "        \n",
    "        hidden1 = torch.cat([hidden1,Intercept_hidden1],dim = 0)\n",
    "        \n",
    "        hidden2 = torch.sigmoid(torch.mm(self.weight_2,hidden1))\n",
    "        \n",
    "        hidden2 = torch.cat([hidden2,Intercept_hidden2],dim = 0)\n",
    "        \n",
    "        y_hat =  torch.sigmoid(torch.mm(self.weight_3,hidden2))\n",
    "        return y_hat ,hidden1 , hidden2\n",
    "    \n",
    "\n",
    "    def loss_function(self,images,label):\n",
    "        \n",
    "        Num = images.shape[1]\n",
    "        y_hat,hidden1,hidden2 = self.y_hat(images)\n",
    "        y = label.view(-1,1)\n",
    "        y=y.float()\n",
    "        # loss = AVERAGE of  ( -ylog(yhat) -(1-y)log(1-yhat) ) + Frobenius norms of Weights\n",
    "        N_CrossEntropy = -torch.mm(torch.log(y_hat),y)-torch.mm(torch.log(1-y_hat),1-y)\n",
    "        self.N1 = self.norm(self.weight_1)# b's norm is deleted in this function (self.norm())\n",
    "        self.N2 = self.norm(self.weight_2)\n",
    "        self.N3 = self.norm(self.weight_3)\n",
    "        Loss = N_CrossEntropy/Num + (self.N1+ self.N2 + self.N3)*(self.regular_lambda/2)\n",
    "        Dif = (y_hat - y.T)\n",
    "        \n",
    "        D = [Dif,hidden1,hidden2] \n",
    "        return float(Loss) , D   \n",
    "    \n",
    "    def gradient_function (self,D,images):\n",
    "        Num = images.shape[1]\n",
    "        Dif,hidden1,hidden2 = D\n",
    "        D_3 = Dif\n",
    "        \n",
    "        # NOTATION: \n",
    "        # ai= g(zi) where i=1,2,3\n",
    "        # z1= matrix Multiprication of (W1,input) + b1, ... ,a3=yhat , \n",
    "        # backpropagation is relevelant to gradient of the cross entropy (propagation)\n",
    "        # D_i = gradient respect to zi \n",
    "        # note that sigmoid(z3) = a3 = yhat. from derivation of the cross entropy with sigmoid,\n",
    "        # we know that D_3 = del Cost/ del a3 * del sig(z3)/ del z3 = (yhat -y / Num) \n",
    "        # where y is the form of (1x Num)\n",
    "        # L0=10000 , L1, L2,L3=1 is number of node in each layer . \n",
    "        # ** L0 = 100x100=10000 .since input images are all Image of 100x100 pixels. \n",
    "        \n",
    "        # suppose 1027 is number of training data (=NUM) (this alg is running in just one batch)\n",
    "        # note that: (W1) = L1xL0, (W2) = L2xL1 ,(W3) = L3xL2 ,\n",
    "        # (hiddeni) = Lix1027 where i=1,2,3 . hiddeni is relavelant to ai\n",
    "        # (training data) = L0x10271x1027)(1027xL2)\n",
    "        gradient_of_weight_3 =  torch.mm(D_3,hidden2.T) *(1/Num)\n",
    "        W3 = self.weight_3[ :,0:-1]\n",
    "        back_sig_2 =hidden2*(1-hidden2)#g'(z2) = g(z2)(1-g(z2))(L2x1027)\n",
    "        back_sig_2 = back_sig_2[ 0:-1 ,:]\n",
    "        Dif_2 = torch.mm(W3.T,D_3)#gradient respect to a2 (L2x1027)\n",
    "        D_2 =Dif_2* back_sig_2#gradient respect to z2 (L2x1027)\n",
    "\n",
    "        gradient_of_weight_2 = torch.mm(D_2,hidden1.T) *(1/Num) # (L2x1027) (1027xL1)\n",
    "        W2 = self.weight_2[:,0:-1]\n",
    "        back_sig_1 =hidden1*(1-hidden1)#g'(z1) (L1x1027)\n",
    "        back_sig_1 = back_sig_1[0:-1,:]\n",
    "        Dif_1 = torch.mm(W2.T,D_2)#gradient respect to a1 (L1x1027)\n",
    "        D_1 = Dif_1*back_sig_1 #gradient respect to z1 (L1x1027)\n",
    "        gradient_of_weight_1 = torch.mm(D_1,images.T)*(1/Num)\n",
    "        \n",
    "        regrad1 = (self.regular_lambda/(2*self.N1))*self.weight_1\n",
    "        regrad1 = regrad1[:,0:-1]\n",
    "        Intercept_regrad1 = torch.zeros(regrad1.shape[0],1)\n",
    "        regrad1 = torch.cat([regrad1,Intercept_regrad1],dim = 1)\n",
    "        \n",
    "        regrad2 = (self.regular_lambda/(2*self.N2))*self.weight_2\n",
    "        regrad2 = regrad2[:,0:-1]\n",
    "        Intercept_regrad2 = torch.zeros(regrad2.shape[0],1)\n",
    "        regrad2 = torch.cat([regrad2,Intercept_regrad2],dim = 1)\n",
    "        \n",
    "        regrad3 = (self.regular_lambda/(2*self.N3))*self.weight_3\n",
    "        regrad3 = regrad3[:,0:-1]\n",
    "        Intercept_regrad3 = torch.zeros(regrad3.shape[0],1)\n",
    "        regrad3 = torch.cat([regrad3,Intercept_regrad3],dim = 1)\n",
    "        \n",
    "        gradient_of_weight_1 += regrad1\n",
    "        gradient_of_weight_2 += regrad2\n",
    "        gradient_of_weight_3 += regrad3\n",
    "        \n",
    "        return [gradient_of_weight_3,\n",
    "                gradient_of_weight_2,\n",
    "                gradient_of_weight_1]\n",
    "        \n",
    "    \n",
    "\n",
    "    \n",
    "   \n",
    "    def accuracy(self,D_3):\n",
    "        false_positive = torch.sum(D_3>=0.5) \n",
    "        false_negative = torch.sum(D_3<-0.5) \n",
    "        total=D_3.shape[1]\n",
    "        hit = total -false_positive-false_negative\n",
    "        return  float(hit.float()/total)\n",
    "        \n",
    "    def networkupdater(self, G,rate):\n",
    "        gradient_of_weight_3 ,gradient_of_weight_2,gradient_of_weight_1 =G\n",
    "        self.weight_1 -= gradient_of_weight_1*rate\n",
    "        \n",
    "        self.weight_2 -= gradient_of_weight_2*rate\n",
    "        \n",
    "        self.weight_3 -=  gradient_of_weight_3*rate\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.361259937286377 6.3127007484436035 6.273599624633789 6.237100601196289 "
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "max_iterations = 500\n",
    "threshold = 0.001\n",
    "train_loss_recoders=[[] for i in range(3)]\n",
    "train_accuracy_recoders=[[] for i in range(3)]\n",
    "test_loss_recoders=[[] for i in range(3)]\n",
    "test_accuracy_recoders=[[] for i in range(3)]\n",
    "gr_weightL = network_updater(464,21,10) # num_node_1 = 464,num_node_2 =21\n",
    "gr_weightA = network_updater(464,21,0.87) # num_node_1 = 464,num_node_2 =21\n",
    "gr_weightS = network_updater(464,21,0.01) # num_node_1 = 464,num_node_2 =21\n",
    "L=0\n",
    "A=1\n",
    "S=2\n",
    "gr_weight = [gr_weightL,gr_weightA,gr_weightS]\n",
    "for i in range(max_iterations):\n",
    "    for j in range(3):\n",
    "        # get and store loss and accuracy \n",
    "        train_loss,train_D = gr_weight[j].loss_function(train_inputs,train_labels)\n",
    "        test_loss,test_D = gr_weight[j].loss_function(test_inputs,test_labels)\n",
    "\n",
    "        train_accuracy = gr_weight[j].accuracy(train_D[0])\n",
    "        test_accuracy = gr_weight[j].accuracy(test_D[0])\n",
    "\n",
    "        train_loss_recoders[j].append((train_loss))\n",
    "        train_accuracy_recoders[j].append(train_accuracy)\n",
    "        test_loss_recoders[j].append((test_loss))\n",
    "        test_accuracy_recoders[j].append(test_accuracy)\n",
    "\n",
    "        #caculate gradient and update weight\n",
    "        gradient = gr_weight[j].gradient_function(train_D, train_inputs)\n",
    "        gr_weight[j].networkupdater(gradient, learning_rate )\n",
    "        if j==1 and i%10 == 0:\n",
    "            print(\"{} \".format(train_loss),end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Large lambda case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(len(test_accuracy_recoders[L])), test_accuracy_recoders[L])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(train_accuracy_recoders[L])), train_accuracy_recoders[L])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(test_loss_recoders[L])), test_loss_recoders[L])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(train_loss_recoders[L])), train_loss_recoders[L])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small lambda case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(len(test_accuracy_recoders[S])), test_accuracy_recoders[S])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(train_accuracy_recoders[S])), train_accuracy_recoders[S])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(test_loss_recoders[S])), test_loss_recoders[S])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(train_loss_recoders[S])), train_loss_recoders[S])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approtiate case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(len(test_accuracy_recoders[A])), test_accuracy_recoders[A])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(train_accuracy_recoders[A])), train_accuracy_recoders[A])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## test loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(test_loss_recoders[A])), test_loss_recoders[A])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## training loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(train_loss_recoders[A])), train_loss_recoders[A])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
